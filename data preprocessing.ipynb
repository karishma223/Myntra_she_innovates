{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb92eb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emot\n",
    "print(\"Imports successful\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1898f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data from posts.json successfully\n",
      "                                inputUrl                   id     type  \\\n",
      "0  https://www.instagram.com/tarini_shah  3242389063277678592    Video   \n",
      "1  https://www.instagram.com/tarini_shah  3124157038573506048  Sidecar   \n",
      "2  https://www.instagram.com/tarini_shah  3101602434564655104    Video   \n",
      "3  https://www.instagram.com/tarini_shah  3409072589826453504    Video   \n",
      "4  https://www.instagram.com/tarini_shah  3404828945839726592  Sidecar   \n",
      "\n",
      "     shortCode                                            caption hashtags  \\\n",
      "0  Cz_R6yURw-J  Tag a person you would witness this peace and ...       []   \n",
      "1  CtbPEYqtc3c  our BIG reveal ⭐️\\n\\nAgasthya and I shot for t...       []   \n",
      "2  CsLGvsytoi5                sapne sajane ki humko mili wajeh ✈️       []   \n",
      "3  C9PdXVaIG__  been wearing this everyday because \\n\\n✨it’s s...       []   \n",
      "4  C9AYeL9vqA-  pick your poison babe, I’m poison either way 🎱...       []   \n",
      "\n",
      "                         mentions                                       url  \\\n",
      "0                              []  https://www.instagram.com/p/Cz_R6yURw-J/   \n",
      "1  [freakinsindia, agasthya.shah]  https://www.instagram.com/p/CtbPEYqtc3c/   \n",
      "2                              []  https://www.instagram.com/p/CsLGvsytoi5/   \n",
      "3                              []  https://www.instagram.com/p/C9PdXVaIG__/   \n",
      "4                     [pumaindia]  https://www.instagram.com/p/C9AYeL9vqA-/   \n",
      "\n",
      "   commentsCount                                       firstComment  ...  \\\n",
      "0             57                        Let's disappear for a while  ...   \n",
      "1            374                               Arey they cousins???  ...   \n",
      "2            107  i think humare hisse ke total maze ek insaan n...  ...   \n",
      "3             41                                   Perfect combo—-😌  ...   \n",
      "4             75   very 90s raveena tandon photoshoot aura of you🤍✨  ...   \n",
      "\n",
      "      ownerId  productType  videoDuration isSponsored  \\\n",
      "0  1944143091        clips         20.840       False   \n",
      "1  1944143091          NaN            NaN       False   \n",
      "2  1944143091        clips         19.533       False   \n",
      "3  1944143091        clips         12.816       False   \n",
      "4  1944143091          NaN            NaN       False   \n",
      "\n",
      "                                         taggedUsers isPinned  \\\n",
      "0  [{'full_name': 'Vogue Japan', 'id': '12236030'...      1.0   \n",
      "1  [{'full_name': 'Agasthya Shah', 'id': '1548701...      1.0   \n",
      "2                                                NaN      1.0   \n",
      "3                                                NaN      NaN   \n",
      "4                                                NaN      NaN   \n",
      "\n",
      "                                           musicInfo  \\\n",
      "0  {'artist_name': 'tarini_shah', 'song_name': 'O...   \n",
      "1                                                NaN   \n",
      "2  {'artist_name': 'KK', 'song_name': 'Hai Junoon...   \n",
      "3  {'artist_name': 'Billie Eilish', 'song_name': ...   \n",
      "4                                                NaN   \n",
      "\n",
      "                                   coauthorProducers  paidPartnership  \\\n",
      "0                                                NaN              NaN   \n",
      "1  [{'id': '1548701749', 'is_verified': True, 'pr...              NaN   \n",
      "2                                                NaN              NaN   \n",
      "3                                                NaN              NaN   \n",
      "4                                                NaN              NaN   \n",
      "\n",
      "   sponsors  \n",
      "0       NaN  \n",
      "1       NaN  \n",
      "2       NaN  \n",
      "3       NaN  \n",
      "4       NaN  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "def read_data(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_json(path)\n",
    "    print(f\"Read data from {path} successfully\")\n",
    "    return df\n",
    "\n",
    "path = \"posts.json\"\n",
    "df = read_data(path)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef61bc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love :smiling_face_with_smiling_eyes: and :glowing_star:\n"
     ]
    }
   ],
   "source": [
    "def replace_emojis_with_text(text: str) -> str:\n",
    "    emot_obj = emot.emot()\n",
    "    try:\n",
    "        emoji_info = emot_obj.emoji(text)\n",
    "        num_emojis = len(emoji_info[\"value\"])\n",
    "        for i in range(num_emojis):\n",
    "            text = text.replace(emoji_info[\"value\"][i], emoji_info[\"mean\"][i])\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the text: {text}. The error is: {e}\")\n",
    "    return text\n",
    "\n",
    "# Test this function\n",
    "print(replace_emojis_with_text(\"I love 😊 and 🌟\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc96886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data from posts.json successfully\n",
      "Starting data processing\n",
      "Data processing completed\n",
      "   id  n_comments  n_likes                                              image\n",
      "0   1         374   255816  https://scontent.cdninstagram.com/v/t51.29350-...\n",
      "1   2          75    32099  https://scontent.cdninstagram.com/v/t39.30808-...\n",
      "2   3          46    38328  https://scontent.cdninstagram.com/v/t39.30808-...\n",
      "3   4         492   130388  https://scontent.cdninstagram.com/v/t51.29350-...\n",
      "4   5        1257   303812  https://scontent.cdninstagram.com/v/t51.29350-...\n",
      "   id                        comments\n",
      "0   1            Arey they cousins???\n",
      "0   1                              Bb\n",
      "0   1                           .b ..\n",
      "0   1                               B\n",
      "0   1  :smiling_face_with_heart-eyes:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to process the DataFrame\n",
    "def process_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(\"Starting data processing\")\n",
    "    \n",
    "    # Filter early to reduce DataFrame size\n",
    "    df = df[df[\"type\"] != \"Video\"]\n",
    "    df = df[df[\"likesCount\"] != -1.0]\n",
    "    df = df[df[\"images\"].notna()]\n",
    "    df = df[df[\"images\"].apply(len) > 0]\n",
    "\n",
    "    # Selecting relevant columns and renaming them\n",
    "    df = df[[\"id\", \"commentsCount\", \"likesCount\", \"latestComments\", \"images\"]]\n",
    "    df.columns = [\"id\", \"n_comments\", \"n_likes\", \"comments\", \"image\"]\n",
    "\n",
    "    # Selecting the first image if there are multiple images\n",
    "    df[\"image\"] = df[\"image\"].str[0]\n",
    "\n",
    "    # Extracting text from comments\n",
    "    df[\"comments\"] = df[\"comments\"].apply(lambda x: [i[\"text\"] for i in x if \"text\" in i])\n",
    "\n",
    "    # Resetting the id\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df[\"id\"] = df.index + 1\n",
    "\n",
    "    # Converting empty lists in comments to np.nan and creating a separate dataframe for comments\n",
    "    df[\"comments\"] = df[\"comments\"].apply(lambda x: x if x else np.nan)\n",
    "    df_comments = df.explode(\"comments\")[[\"id\", \"comments\"]]\n",
    "\n",
    "    # Replace emojis in comments with their text descriptions\n",
    "    df_comments[\"comments\"] = df_comments[\"comments\"].apply(replace_emojis_with_text)\n",
    "\n",
    "    # Removing comments column from the original dataframe\n",
    "    df = df.drop(\"comments\", axis=1)\n",
    "\n",
    "    print(\"Data processing completed\")\n",
    "    return df, df_comments\n",
    "\n",
    "# Test this function\n",
    "path = \"posts.json\"\n",
    "df = read_data(path)\n",
    "df_processed, df_comments_processed = process_data(df)\n",
    "print(df_processed.head())\n",
    "print(df_comments_processed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c66568b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully\n"
     ]
    }
   ],
   "source": [
    "def save_data(df: pd.DataFrame, df_comments: pd.DataFrame) -> None:\n",
    "    df.to_csv(\"only_posts.csv\", index=False)\n",
    "    df_comments.to_csv(\"posts_comments.csv\", index=False, sep=';')\n",
    "    print(\"Data saved successfully\")\n",
    "\n",
    "# Test this function\n",
    "save_data(df_processed, df_comments_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6137bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data from posts.json successfully\n",
      "Read data from posts2.json successfully\n",
      "Starting data processing\n",
      "Data processing completed\n",
      "Data saved successfully\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    path = \"posts.json\"\n",
    "    path2 = \"posts2.json\"\n",
    "    \n",
    "    # Read, process and save the data\n",
    "    df_1 = read_data(path)\n",
    "    df_2 = read_data(path2)\n",
    "    df = pd.concat([df_1, df_2])\n",
    "    df, df_comments = process_data(df)\n",
    "    save_data(df, df_comments)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fadb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
